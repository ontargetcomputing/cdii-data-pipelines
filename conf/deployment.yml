# build:
#   no_build: true

# Custom section is used to store configurations that might be repetative.
# Please read YAML documentation for details on how to use substitutions and anchors.
custom:

  email_notifications_props: &email_notifications_props
    email_notifications:
      on_failure:
        - richard@ontargetcomputing.net 

  basic-cluster-props: &basic-cluster-props
    spark_version: "10.4.x-cpu-ml-scala2.12"

  ci-cluster: &ci-cluster
    new_cluster:
      <<: *basic-cluster-props
      num_workers: 1
      cluser_id: "0124-003646-pqv9062d"
      node_type_id: "Standard_DS3_v2"



environments:
  ci:
    workflows:
      # - name: "hello-world-job"
      #   <<: 
      #     - *email_notifications_props
      #   <<: *ci-cluster
      #   spark_python_task:
      #     python_file: "file://cdii_data_pipelines/hello_world.py"

    - name: "New Wildfire Pipeline"
      tasks:
        - task_key: "wildfire_points_bronze"
          existing_cluster_name: "Richard's Cluster"
          spark_python_task:
            python_file: "file://cdii_data_pipelines/tasks/hazard/wildfire/wildfire_points_bronze_task.py"
            parameters: [ "--conf-file", "file:fuse://conf/tasks/hazard/wildfire/wildfire_points_bronze_task.ci.yml" ]         
        - task_key: "wildfire_perims_bronze"
          existing_cluster_name: "Richard's Cluster"
          spark_python_task:
            python_file: "file://cdii_data_pipelines/tasks/hazard/wildfire/wildfire_perims_bronze_task.py"
            parameters: [ "--conf-file", "file:fuse://conf/tasks/hazard/wildfire/wildfire_perims_bronze_task.ci.yml" ]         

    # - name: "WIP-Wildfires"
    #     tasks:
    #       - task_key: "set-batchid"
    #         <<: *ci-cluster
    #         spark_python_task:
    #             python_file: "file://cdii_data_pipelines/tasks/set_batchid.py"
    #             # this call supports all standard pytest arguments
    #             parameters: [ "--conf-file", "file:fuse://conf/tasks/hazard/wildfire/current/ci/extract.yml" ]        
    #       - task_key: "extract-points"
    #         depends_on: 
    #           - task_key: set-batchid
    #         <<: *ci-cluster
    #         spark_python_task:
    #             python_file: "file://cdii_data_pipelines/tasks/hazard/wildfire/current/extract_points.py"
    #             # this call supports all standard pytest arguments
    #             parameters: [ "--conf-file", "file:fuse://conf/tasks/hazard/wildfire/current/ci/extract.yml" ]
    #       - task_key: "extract-perimeters"
    #         depends_on: 
    #           - task_key: set-batchid
    #         <<: *ci-cluster
    #         spark_python_task:
    #             python_file: "file://cdii_data_pipelines/tasks/hazard/wildfire/current/extract_perimeters.py"
    #             # this call supports all standard pytest arguments
    #             parameters: [ "--conf-file", "file:fuse://conf/tasks/hazard/wildfire/current/ci/extract.yml" ]          